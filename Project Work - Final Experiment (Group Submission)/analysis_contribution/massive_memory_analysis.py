# -*- coding: utf-8 -*-
"""Massive Memory Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s425jSClt8KF6oqUVIwIXOTAugl11Fbf

##0. Setting Up: Loading the tidyverse packages
Before working through this notebook, make sure that your runtime is set to use R (rather than python). This should be set already, but you can double-check by selecting the following from the menu at the top of the notebook.

  Runtime > Change runtime type

Then make sure that R appears in the drop-down menu under runtime type.

This first part of the code just installs and loads the R packages we want to use for the following analyses.
"""

#Install packages we want to use

#this loads a helper function for installing R packages
source('https://raw.githubusercontent.com/COGS119/tutorials/refs/heads/main/R/load_install_packages.R')

#specify the name of all packages we want to use her
packages_to_apt_install = c('tidyverse')

#install packages specified above (note that we're using our old friend the for loop, this time in R syntax) into our google colab environment
#For more: https://www.w3schools.com/r/r_for_loop.asp
for (package in packages_to_apt_install) load_install_package(package, apt=TRUE)

#load packages we want to use
library(tidyverse)
library(scales)

#set some basic plotting defaults
theme_set(theme_minimal(base_size = 18))

#check the version of R used
print(R.version.string)

"""##1. Load the data

In this first section, we load in the data from the experiment and inspect it.

We've already done some significant processing to your data (consult your GitHub project page for detailed code, if you're curious!). Note: If you notice that any key information is missing from the data, please check with your instructor.

"""

group_name <- "massive_memory"
#read in your data
processed_data <- read_csv(paste0("https://raw.githubusercontent.com/COGS119/group_fa24_",group_name,"/refs/heads/main/data/processed_data/",group_name,"-processed-data.csv"))

"""Let's first take a look at your data."""

glimpse(processed_data)

unique(processed_data$participant_id)

unique(processed_data$repeat_false_alarm_rate)

"""###1.1. Codebook

A first important step is to understand your data.

Please complete this section to include a full codebook including a description of each column in your dataset. To get you started, we've included descriptions of the first few columns.


*   **participant_id**: the participant code entered by the participant
*   **random_id**: a random code generated for each session by the experiment (identifies unique sessions)
*   **repeat_false_alarm_rate**: the average rate for participants during the n-back task who falsely pressed spacebar for the falsely recalled item during the memory task.

##2. Descriptives

In this section, look at the basic overall descriptives, e.g., overall average responses for each condition.

If you have multiple responses per participant, make sure to first cluster/ average your data within participant before deriving an overall average estimate.

Make sure that your averages allow you to derive an estimate of your central condition difference (e.g., a condition difference).

A few other rules to keep in mind:
- typically, we look at reaction times *only* for correct responses
- if you are using a scale, make sure you are transforming any items that are reverse-coded.
"""

#take a look at the number of distinct responses
processed_data |>
  distinct(random_id,participant_id)

processed_data$is_right

proc_data_stat <- processed_data |>
  group_by(participant_id, trial_kind) |>
  summarise(accuracy=mean(is_right), .groups = "drop")
    # Martin: I jumped in and made a small correction here to support! (you want sd(is_right), not sd(accuracy))
    # Note that you would actually want to compute sd/ sem only at your *next* step when you average across participants (next code chunk)
proc_data_stat

ggplot(proc_data_stat, aes(x=participant_id, y=accuracy, fill=trial_kind)) +
  geom_bar(stat="identity", position=position_dodge()) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 50, hjust = 1))

processed_data |>
    group_by(trial_kind) |>
      summarise(
      accuracy = mean(is_right),
      sd_correct = sd(is_right),
      n_obs = n(),
      sem = sd_correct / sqrt(n_obs),
      ci_lower = accuracy - 1.96 * sem,
      ci_upper = accuracy + 1.96 * sem)

summary_stat <- proc_data_stat |>
  group_by(trial_kind) |>
    summarise(
      mean_accuracy = mean(accuracy),
      sd_accuracy = sd(accuracy),
      n_obs = n(),
      sem = sd(accuracy) / sqrt(n_obs),
      ci_lower = mean_accuracy - 1.96 * sem,
      ci_upper = mean_accuracy + 1.96 * sem)
summary_stat

"""## 3. Plot

Create a plot of your central effect or effects.

Things to keep in mind:
- **clear axis labels:** make sure your axis labels are clear (don't just use the column names, try to indicate the units for dependent measures, e.g. "Reaction Time (in ms)")
- **variability across participants:** whenever possible, try to represent both the overall average and the underlying variability across participants (e.g., include dots or violin plots of individual participant averages)
- **error bars/ bands:** a good plot will also include error bars/bands for average estimates (e.g., 95% confidence intervals or standard errors)

"""

mem_performance_plot <- ggplot(summary_stat, aes(x=trial_kind, y=mean_accuracy, fill=trial_kind)) +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "black", size = 0.5, ) +
  geom_bar(stat="identity", width=0.75) +
  geom_errorbar(aes(ymin=ci_lower, ymax=ci_upper), width=.1,
                position=position_dodge(.9)) +
  geom_text(aes(label = round(mean_accuracy * 100)),
            vjust = -3, color = "black", size = 5) +
  geom_point(data = proc_data_stat, aes(x = trial_kind, y = accuracy),
            width = 0.2, size = 1, alpha = 0.6, color = "blue") +
  scale_y_continuous(labels = percent,
                     limits = c(0, 1),
                     expand = expansion(0,0)) +
  labs(title = "Memory Performance Between State and Exemplar Trials",
       x = "Trial Type",
       y = "Percent Correct") +
  scale_fill_grey() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "none") +
  theme_minimal()
mem_performance_plot

"""Additional EDA on data

processed_data$is_right
"""

processed_data$is_right

# Confidence vs. Correct Trials
processed_data$is_right <- as.factor(processed_data$is_right)

ggplot(processed_data, aes(x = is_right, y = confidence_response, fill = is_right)) +
  geom_violin(alpha = 0.7, trim = FALSE) +
  scale_fill_manual(values = c("0" = "lightcoral", "1" = "lightblue")) +
  labs(
    title = "Confidence Scores by Trial Correctness",
    x = "Correctness (0 = Incorrect, 1 = Correct)",
    y = "Confidence Score"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")

test_trial <- processed_data |>
  select(participant_id, trial_number, time_elapsed, trial_kind, rt, confidence_response, is_right) |>
  group_by(participant_id) |>
  mutate(time_from_start = time_elapsed - first(time_elapsed)) |>
  ungroup()
test_trial

# Ensure participant and time elapsed are treated appropriately
test_trial$participant_id <- as.factor(test_trial$participant_id)

# Line plot of accuracy over time (time elapsed on x-axis)
ggplot(test_trial, aes(x = time_from_start, y = is_right, color = participant_id)) +
  geom_line(alpha = 1, size = 0.8) +
  geom_point(size = 1, alpha = 0.8) +
  facet_wrap(~participant_id, ncol = 3)
  labs(
    title = "Confidence Scores Over Time (Elapsed Time)",
    x = "Time Elapsed (seconds)",
    y = "Confidence Score",
    color = "Participant") +
  theme_minimal(base_size = 14) +
  theme(strip.text = element_text(size = 10), # Adjust size of facet labels
  panel.spacing = unit(1, "lines")) +
  theme(legend.position = "none")

# Confidence Overtime between participants

ggplot(test_trial, aes(x = time_from_start, y = confidence_response, color = participant_id)) +
  geom_line(alpha = 1, size = 0.8) +
  geom_point(size = 1, alpha = 0.8) +
  facet_grid(participant_id ~ .)
  labs(
    title = "Confidence Scores Over Time (Elapsed Time)",
    x = "Time Elapsed (seconds)",
    y = "Confidence Score",
    color = "Participant") +
  theme_minimal(base_size = 14) +
  theme(strip.text = element_text(size = 10), # Adjust size of facet labels
  panel.spacing = unit(1, "lines")) +
  theme(legend.position = "none")

ggplot(processed_data, aes(x = participant_id, y = repeat_hit_rate)) +
  geom_bar(stat="identity") +
  labs(title = "Participant Repeat Hit Rate",
       x = "Participant",
       y = "Repeat Hit Late") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

"""For participants: "giraffe", "jaguar", and "panda", they had a zero repeat hit rate, indication of non-participation in the n-back task."""

library(forcats)

# Reordering participants' accuracies to be ascending
proc_data_stat$participant_id <- fct_reorder(proc_data_stat$participant_id, proc_data_stat$accuracy)

ggplot(proc_data_stat, aes(x = participant_id, y = accuracy, fill = participant_id)) +
  geom_bar(stat="identity") +
  labs(title = "Participant Accuracy",
       x = "Participant",
       y = "Accuracy") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

"""Panda, giraffe, and jaguar have the lowest, second lowest, and fourth lowest rated accuracies respectively."""

test_trial$is_right <- as.numeric(test_trial$is_right)

updated_proc <- proc_data_stat |>
  filter(!participant_id %in% c("panda", "giraffe", "jaguar")) |>
  group_by(trial_kind) |>
  summarise(
      mean_accuracy = mean(accuracy),
      sd_accuracy = sd(accuracy),
      n_obs = n(),
      sem = sd(accuracy) / sqrt(n_obs),
      ci_lower = mean_accuracy - 1.96 * sem,
      ci_upper = mean_accuracy + 1.96 * sem)
updated_proc

nback_mem_plot <- ggplot(updated_proc, aes(x=trial_kind, y=mean_accuracy, fill=trial_kind)) +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "black", size = 0.5, ) +
  geom_bar(stat="identity", width=0.75) +
  geom_errorbar(aes(ymin=ci_lower, ymax=ci_upper), width=.1,
                position=position_dodge(.9)) +
  geom_text(aes(label = round(mean_accuracy * 100)),
            vjust = -3, color = "black", size = 5) +
  geom_point(data = proc_data_stat, aes(x = trial_kind, y = accuracy),
            width = 0.2, size = 1, alpha = 0.6, color = "blue") +
  scale_y_continuous(labels = percent,
                     limits = c(0, 1),
                     expand = expansion(0,0)) +
  labs(title = "Memory Performance for N-Back Participants",
       x = "Trial Type",
       y = "Percent Correct") +
  scale_fill_grey() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "none") +
  theme_minimal()
nback_mem_plot

par(mfrow = c(1, 2))

mem_performance_plot

nback_mem_plot

# Reaction Time Comparison State vs. Exemplar
rt_test_trial <- test_trial|>
  group_by(trial_kind) |>
  summarise(rt_acc = mean(rt))
rt_test_trial

ggplot(rt_test_trial, aes(x=trial_kind, y=rt_acc, fill=trial_kind)) +
  geom_bar(stat="identity", width=0.5) +
  labs(title = "Reaction Time Between Categories",
       x = "Trial Kind",
       y = "Average Reaction Time") +
  scale_fill_grey() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "none") +
  theme_minimal()

install.packages("corrplot")

ggplot(merged_data, aes(x = repeat_hit_rate, y = overall_accuracy)) +
  geom_point(color = "black", size = 2, alpha = 0.6) +
  scale_y_continuous(labels = percent,
                     limits = c(0, 1),
                     expand = expansion(0,0)) +
  labs(title = "Repeat Hit Rate vs. Overall Accuracy", x = "Repeat Hit Rate", y = "Overall Accuracy") +
  theme_minimal()

library(corrplot)

articipant_mean_accuracy <- proc_data_stat %>%
  group_by(participant_id) %>%
  summarise(overall_accuracy = mean(accuracy))
merged_data <- merge(participant_mean_accuracy, processed_data, by = "participant_id")

cor_data <- merged_data %>%
  select(repeat_hit_rate, overall_accuracy)

cor_matrix <- cor(cor_data, use = "complete.obs")
corrplot(cor_matrix, method = "shade", type = "upper", tl.col = "black", tl.srt = 45)

"""## 4. Inference [optional]

Can you derive statistical tests or models that investigate your central question of interest? A good starting point will be to look at the Results section of your replication article.


"""